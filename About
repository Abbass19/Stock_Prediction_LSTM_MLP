Here we are trying to make a cleaner version of the same time for the 5th time maybe in a row.
However this time is different. As there are many changes to be done. Like defining the real thing we intend to do here.

What is this code:

    This code is a refactoring of the previous successful code base called Task_1_Agent_Training specially
    the version 3 the only one that gave reasonable response.

What is different about this code:
    1. I will use the style of structuring I saw in the code I saw named LTM_Long_Short thing. This way splits
       the coding from testing. Through creating Jupyter Notebook files used to test things in logical sort. Test
       the train functions. The TPG linkage function. The fine-tune functions. The model's performance. Saving and
       loading the models. (In conclusion all functions will be checked including correction error and stuff). This
       testing will consolidate the code. When We are sure a code work we should document that throw saying for
       example this code is working as demonstrated by the note book number 5 for example.

    2. It will mainly include the LSTM models that are primary focus here both for prediction and error correction
    3. The strict usage of TPG functions as required by the supervisor
    4. A main script that moves intelligently between the things that I want. Training Model and presenting the results.
       Training the correction model in a specific architecture. Demonstrating the results. (It could have a small part
       to compare LSTM and MLP in time series)
    5. The data importing function uses Standard Scaler and fit the scaler to the training data and applies that transform
       to the testing data to avoid any data leakage.
    6. Another problem solved here is the following. The evaluate function was used on prediction and data in the model layer.
       Which is up to my understanding wrong. As to my understanding, the loss should be calculated over data that is post-processed.
       So that the error is linked here with the real difference in stock and not in the logarithmic thing.


Logical Steps to be Done:
    1. Make the structure that consists of NoteBooks (Including the experimentation of each thing on it's own) and
       APIs (Models MLP and LSTM. We could as well isolate the functions for each one of those) and Plots (The images
       generated by each model on it's own) and Data (like my_data and the correction data split into train and test)
       and Model's saved

    2. Pick Up functions from the past code and test each one of them carefully to build the entire engine as needed.
    3. Research on Models architecture decisions for LSTM.
    4. Test the engine including preprocessing and training and plotting things
    5. Make the test for the LSTM Model Prediction
    6. Decide for the last model and then start the trip of fine-tuning the other correction model.

